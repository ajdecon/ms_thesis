\chapter{Computerized Tracking of Anisotropic Colloids}
\label{ch:comp-tracking}

\section{Introduction}

Confocal laser scanning microscopy (CLSM) is a powerful technique for the study of three-dimensional
structure in fluorescent materials. When applied to fluorescent colloids, CLSM allows the observation
of individual particles and provides detailed data about the geometric configuration of the 
material.~\cite{weitz-confocal}
This data alone can be used to derive a great deal
of information about the material, such as the distribution of number of nearest neighbors and
the pair distribution function (PDF). Repeated observations at regular intervals allow for dynamical
measurements of parameters such as the diffusion constant.~\cite{weitz-confocal,crocker-grier-spheres}

However, 
the production of useful 3D structural information requires more than just a powerful imaging technique: it also
requires powerful computational analysis tools to translate image data into a list of particles and positions, and
to calculate relevant physical characteristics from these positions.  In addition, the behavior of non-spherical colloids
is governed not only by the relative positions of the particles but also their orientations. Developing an
understanding of anisotropic colloids
therefore calls for the development of image processing techniques for the extraction and analysis of
structural data from microscopy images.

In Section~\ref{sec:track-background}, we describe techniques from the literature for the tracking of 
spherical and ellipsoidal colloids.  Section~\ref{sec:rod-tracking} develops an algorithm for the identification
and tracking of rod-like colloids fabricated by stop-flow lithography, and Section~\ref{sec:track-results}
demonstrates the use of this algorithm to track diffusing and self-assembled particles.
Appendix~\ref{sec:matlab-implementation} describes the implementation in Matlab of the algorithm developed in 
Section~\ref{sec:rod-tracking}.

\section{Background}
\label{sec:track-background}

\subsection{Tracking of spherical colloids}

In a 1996 paper in the \textit{Journal of Colloid and Interface Science}~\cite{crocker-grier-spheres},
John Crocker and David Grier outline a five-stage procedure for the tracking of
spherical colloidal particles.  This algorithm was implemented in IDL and has become the standard for carrying out 
3D tracking of spherical particles. It has since been ported to other environments such as 
Matlab~\cite{blair-dufrense-matlab, kilfoil-matlab} and LabView~\cite{optical-trapping-group} which are
also commonly used in the scientific community.

\subsubsection{Image restoration}
\label{sec:band-pass}

CLSM imaging of colloidal suspensions may introduce camera noise and geometric distortions which 
lead to images which do not
accurately describe the geometry of the suspension. 
These effects can be compensated for by applying a spatial band-pass filter 
to the image $A$, which is composed of two parts.

The first part is a boxcar average over a region of extent $2w + 1$, where $w$ is an integer
larger than a single sphere's apparent radius in pixels, but smaller than an intersphere separation:

\begin{center}\begin{equation}A_w(x,y) = \frac{1}{(2w+1)^2} \sum_{i,j=-w}^w A(x+i,y+j)
\end{equation}\end{center}

The second part is a convolution of the image with a Gaussian surface of revolution with 
half-width $\lambda_n \approx $ 1 pixel:

\begin{center}\begin{equation}A_{\lambda_n}(x,y) = \frac{1}{B} \sum_{i,j=-w}^w A(x+i,y+j)\exp{\left(-\frac{i^2+j^2}{4\lambda_n^2}\right)}
\end{equation}\end{center}

with normalization B = $[\sum_{i=-w}^w \exp{-(i^2/4\lambda_n^2)}]^2$.

These two filters can be applied simultaneously in a single step using the convolution kernel

\begin{center}\begin{equation}K(i,j) = \frac{1}{K_0} \left[ \frac{1}{B} \exp{ \left( -\frac{i^2+j^2}{4\lambda_n^2} \right)} -
\frac{1}{(2w+1)^2} \right]
\end{equation}\end{center}

The normalization constant $K_0 = 1/B[\sum_{i=-w}^w \exp{-(i^2/2\lambda_n^2)}] - (B/(2w+1)^2)$ facilitates comparison
among images filtered with different values of $w$.

\subsubsection{Locating particles}

Particles are located by identifying local brightess maxima within an image. A pixel is identified
as a candidate if no other pixel within a distance $w$ is brighter, where $w$ is the same value used in
the filtering step. This was implemented by Crocker and Grier using a gray-scale dilation 
operation.~\cite{soille-book}

\subsubsection{Refining location estimates}

Having located a brightness maximum at $(x, y)$ which is presumably near
a sphere's geometric center at $(x_0, y_0)$, additional refinements are possible
which may achieve sub-pixel accuracy.  An offset $(\epsilon_x, \epsilon_y)$ is
calculated according to:

\begin{center}
\begin{equation}
\left( \begin{array}{c} \epsilon_x \\ \epsilon_y \end{array} \right) 
= \frac{1}{m_0}
\sum_{i^2+j^2 \leq w^2} 
\left( \begin{array}{c} i \\ j \end{array} \right)
A(x+i,y+j)
\end{equation}
\end{center}

Here, $m_0 = \sum_{i^2+y^2 \leq w^2} A(x+i,y+j)$ is the integrated brightness of the
sphere's image. The refined location estimate is then $(x_0, y_0) = (x+\epsilon_x, y+\epsilon_y)$.
If either $|\epsilon_x|$ or $|\epsilon_y|$ exceeds 0.5, the candidate centroid location can be moved and the
refinement recalculated.

\subsubsection{Noise discrimination and tracking in depth}

During the centroid refinement calculations, two moments of each sphere image's brightness 
distribution are calculated:

\begin{center}\begin{equation}
m_0 = \sum_{i^2+y^2 \leq w^2} A(x+i,y+j)
\end{equation}\end{center}

\begin{center}\begin{equation}m_2 = \frac{1}{m_0} \sum_{i^2+j^2 \leq w^2} (i^2 + j^2)A(x+i,y+j)
\end{equation}\end{center}

where $(x,y)$ are the refined centroid locations.  The distribution of the $(m_0,m_2)$ data reflects the
sphere's positions along the direction normal to the imaging plane, and a control experiment using a 
monolayer of particles is used to calibrate this data.

\subsubsection{Linking locations into trajectories}
\label{sec:time-tracking}

Having located the colloidal particles in a sequence of video images, it is possible to 
match particle locations in each image with corresponding locations in later images to produce
trajectories.  This requires determining which particle in a given image
most likely corresponds to one in the preceding image.  The tracking of 
multiple particles requires that we seek the most probable set of $N$ identifications 
between $N$ locations in two consecutive images. If the particles are indistinguishable (as for
monodisperse colloidal particles), this likelihood can be estimated only using relative
proximity.

The probability that a single Brownian particle will diffuse a distance $\delta$ in the plane 
in time $\tau$ is

\begin{center}\begin{equation}P(\delta|\tau) = \frac{1}{4\pi D\tau} \exp{ \left( -\frac{\delta^2}{4D\tau} \right) }
\end{equation}\end{center}

where $D$ is the particle's self-diffusion coefficient.  For an ensemble of $N$ noninteracting
identical particles, the corresponding probability distribution is the product of the 
single-particle results:

\begin{center}\begin{equation}P({\delta_i}|\tau) = \left( \frac{1}{4\pi D\tau} \right)^N 
\exp{ \left( -\sum_{i=1}^N \frac{\delta_i^2}{4D\tau} \right) }
\end{equation}\end{center}

Each label assignment can be thought of as a bond drawn between a pair of particles
in consecutive frames.  $P({\delta_i}|\tau)$ is calculated for all possible combinations which
represent a displacement below some characteristic length scale $L$, selected by the user based on
the experimental conditions.

\subsection{Rod tracking}

While the algorithm by Crocker and Grier is used widely for tracking spherical particles, it 
cannot deal with particles which have an anisotropic shape and some orientation. 
To begin to deal with simple anisotropy, Mohraz and Solomon developed an algorithm for tracking 
ellipsoidal colloidal rods based on the spherical tracking algorithm.~\cite{rods-mohraz, solomon-dynamics}

\figone{fig:pmma-fabrication}{figures/computerized-tracking/pmma-fabrication.png}{0.6\linewidth}{
(a) Synthesis of PMMA-g-PDMS spheres, (b) curing of the PDMS matrix, (c) uniaxial deformation,
(d) rod harvesting.}

Poly(methyl methacrylate)-g-poly(dimethylsiloxane) (PMMA-g-PDMS) fluorescent colloidal spheres were
synthesized and suspended in a polymerizable liquid silanol-terminated PDMS, which was then cured to form a solid 
matrix.  This matrix was then heated above the glass transition temperature 
of PMMA-g-PDMS and subjected to 
uniaxial stretching, then cooled while still deformed.  The rods were then harvested from the 
elastic film by chemical degredation, and transferred to a cyclohexyl bromide (CXB) solution.
This rod suspension was then visualized via CLSM, and 
subjected to a three-stage image processing algorithm to determine the position and orientation of each rod.

\subsubsection{Image restoration}

To correct for imaging distortions and local noise, voxels are convoluted with neighbors found within a local
distance $w$ using a Gaussian function, where $w$ is of the order of the rod half-width. The resulting
voxel intensity $A(x,y,z)$ is

\begin{center}
\begin{equation}
A(x,y,z) = \frac{1}{B(x,y,z)} \sum_{i,k,j=-w}^w A(x+i,y+j,z+k) 
\exp{ \left( -\frac{i^2+j^2+k^2}{6\lambda^2} \right)}
\end{equation}
\end{center}

where $B$ is a normalization constant and $\lambda$ is defined to be 1 for these experiments.

\subsubsection{Rod backbone identification}

\figone{fig:local-line-max}{figures/computerized-tracking/local-line-max.png}{0.3\linewidth}{
Local line maximum criterion.}

Rod backbones are identified using a local line maximum criterion.  Each voxel is compared with its immediate 
neighbors in all directions along lines with length $2w+1$.  If a candidate voxel is found to be the brightest
point on more than a critical fraction of these lines (typically 70\%), it is considered to be a backbone
pixels.  Backbone pixels are then grouped together by cluster analysis to form rod backbones.

\figone{fig:pmma-rod-backbones}{figures/computerized-tracking/backbone-assignment.png}{0.6\linewidth}{
Rod backbone assignments (a) in a stretched film and (b) in a sediment structure.}

\subsubsection{Orientation and centroid calculation}
\label{sec:orient-calculate}

\figone{fig:coordinates}{figures/computerized-tracking/rod-schematic-solomon.png}{0.4\linewidth}{
Positional and orientational coordinates for colloidal rods.~\cite{mohraz-rods}}

Once the backbone pixels for a given rod have been identified, the position and orientation of each rod may
be determined based on these pixels' locations.  Each rod's geometric configuration can be
completely specified by three positional coordinates, $x$, $y$ and $z$, and two
orientational coordinates $\theta$ and $\phi$, as shown in Figure~\ref{fig:coordinates}.

The rod's center-of-mass position may be calculated
straightforwardly based on a simple average over the positions of the backbone pixels.  In 
Equations \ref{eq:x-cent}--\ref{eq:z-cent}, $r_{0,i}$ represents the center-of-mass of coordinate $r$ for 
rod $i$.  $S_i$ is the number of identified backbone pixels associated with that rod, and $s$ is the index
variable summing over that set.

\begin{equation}
\label{eq:x-cent}
x_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} x_{s,i}
\end{equation}
\begin{equation}
\label{eq:y-cent}
y_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} y_{s,i}
\end{equation}
\begin{equation}
\label{eq:z-cent}
z_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} z_{s,i} 
\end{equation}

Calculating orientation is somewhat more complex.  First, for each dimension $r$, the quantity
$|<l_r^2>^{1/2}|$ is calculated (Equations~\ref{eq:x-len}--\ref{eq:z-len}). 
Geometrically, this is the size of the projection of the rod's length
onto the axis $r$.
Once these dimensions have been calculated, the angles $\phi$ and $\theta$ may be 
determined according to \ref{eq:phi} and \ref{eq:theta}, respectively.

\begin{equation}
\label{eq:x-len}
|<l_x^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (x_{s,i} - x_{0,i} )^2 \right]^{1/2}
\end{equation}
\begin{equation}
\label{eq:y-len}
|<l_y^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (y_{s,i} - y_{0,i} )^2 \right]^{1/2}
\end{equation}
\begin{equation}
\label{eq:z-len}
|<l_z^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (z_{s,i} - z_{0,i} )^2 \right]^{1/2}
\end{equation}

\begin{equation}
\label{eq:theta}
\theta_i = \cos^{-1} \left(\frac{<l_z^2>_i^{1/2}}{<l^2>_i^{1/2}} \right)
\end{equation}
\begin{equation}
\label{eq:phi}
\phi_i = \tan^{-1} \left(\frac{<l_y^2>_i^{1/2}}{<l_x^2>_i^{1/2}} \right)
\end{equation}

\section{Algorithm for tracking SFL rods}
\label{sec:rod-tracking}

Our method for locating and tracking rods produced by stop-flow lithography (SFL) draws heavily from that published by 
Mohraz and Solomon for tracking PMMA rods.~\cite{rods-mohraz}.
While this algorithm performs very well for a restricted class of rods, it fails in cases where the particle
cross-section is not circular, and points near the particle backbone are not guaranteed to produce higher 
intensities than their immediate neighbors.  This is the case for our ``rods'' produced by stop-flow
lithography (SFL), in which the sides of the rods are relatively flat due to the fabrication
geometry. These particles have correspondingly flat fluorescence profiles, and require a more complex analysis
to calculate a ``backbone''.

We have developed an algorithm for processing 2D and 3D CLSM data of fluorescent SFL rods to
produce position and orientation data.  Starting from raw CLSM images, this algorithm can be divided
into several phases, including (i) image cleanup; (ii) segmentation; (iii) skeletonization;
(iv) position calculation; and
(v) particle tracking over a time series.  

A note on terminology: the algorithm described below is identical for both 2D and 3D images, as all
operations are defined for both cases and used identically. However, where the individual elements of
2D images are referred to as pixels, the elements of 3D images are generally referred to as voxels.
For simplicity, all such elements are referred to as pixels in the explanation below.

\subsection{Image cleanup}

For any given set of images, two different image cleanup techniques were used for test
images, and the best result was used for the entire set.

The first method was a spatial bandpass filter, described in 
Section~\ref{sec:band-pass} and implemented in Matlab by Blair and
Dufrense~\cite{blair-dufrense-matlab}. This filter takes two parameters, the characteristic scale
of image noise (generally equal to one pixel) and the typical particle size.  This 
generally works well,
but has issues in images with multi-pixel noise.

While the band-pass performed well on some images, many experiments produced data with noise or
extraneous features which did
not easily yield to the bandpass operation. This can be attributed to the fact that SFL fabrication produces
solutions which have some amount of fluorescent monomer present in the liquid as well as the particles, which
could not always be removed effectively.  A second method was devised using morphological
operations to better neutralize non-particle features.

This method may be divided into five steps. First, the 
image is run through a morphological top-hat transform. This transform is used to account for the effects of
uneven illumination in the image. Then the image is thresholded to produce a binary image, where the 
background is black and the fluorescent features are white. The threshold is selected such that pixels which 
are part of the particle volume are never assigned to the background; Otsu's criterion was found to be reliable
for this.~\cite{otsu-threshold}  Next, a binary opening is applied with an isotropic structuring element to
suppress small features. The size of the structuring element is selected manually by the user, but a 
reliable choice was found to be a diameter roughly equal to half the width of the typical rod. 

At this point a binary image has been produced which suppresses most non-particle features, but morphological
image operations are not guaranteed to preserve shape and orientation of image features.  To retain the noise suppression
but regain the original shape, we perform one additional morphological dilation using the same structuring element to
guarantee that the foreground regions fully overlap with the rods, then perform a binary AND between the result and the
original image. This is effectively equivalent to using the result of our morphological operations as a mask on
the original, suppressing
all pixels which are marked as background.

\subsection{Segmentation}

The next step of the algorithm is image segmentation, in which individual particles are identified and each pixel
in the image is assigned to a specific particle, or to the background. 

%This is especially important in the study 
%of Janus rods, which are come into contact during self-assembly and which therefore often touch or overlap in 
%CLSM images. 

First, the image is thresholded to produce a binary image, with a threshold selected such that all pixels which
are part of the rods are assigned to the foreground. Again, this may generally be accomplished through the use of 
Otsu's criterion.~\cite{otsu-threshold}

Second, the Euclidean distance transform is 
calculated.~\cite{matlab-bwdist}  In this step, each foreground pixel is assigned a number which
gives the distance between this pixel and the nearest background pixel. In this algorithm, the distance measure used
is simple Euclidean distance, calculated center-to-center between this pixel and the closest background pixel.  Alternative
distance measures such as the ``chessboard'' measure may also be used to speed up computation, but these measures were
found to negatively impact segmentation.  To prepare the image for watershed segmentation, the distance 
transform is transformed such that all distances are made
negative, while the background remains at a flat zero. 
An h-minima transform is applied to remove small local minima
due to noise in the image.~\cite{soille-book}

The primary segmentation step is the watershed 
transform.~\cite{matlab-watershed} In this transform, a gray-level image is viewed as
a topographic relief map where the pixel values represent altitude. A drop of water falling on a relief 
surface will run down to a local minimum, and many drops will fill any 
local minima present until the basins meet.
Implementations of the watershed transform use this concept to calculate the boundaries between catchment basins,
fully segmenting the image.  The number of basins is calculated either by using local minima in the image, or by 
pre-assigning a set of markers.  In our algorithm, we generally use the Matlab implementation of \texttt{watershed} which
uses the local minima method.  A local-minima based watershed transform generally does result in some 
over-segmentation, but this effect can be mitigated by using the h-minima transform to remove 
artifacts.  While a marker-based technique would avoid this issue, it is much more cumbersome when a large number
of images must be processed.

\texttt{watershed} outputs an image which labels each pixel according to a region ID number, and labels both background
and foreground pixels with these regions. To restrict these labels so that the background is labeled separately, all 
watershed pixels which correspond to background-valued pixels in the thresholded image are assigned a label number of zero.

\subsection{Skeletonization}

Once we have identified which image pixels belong to each particle, we need to put this data into a form from
which reliable position and orientation information can be calculated.  While it is tempting to simply
calculate the centroid and associated moments from the raw pixel data, this can be problematic when working with
time-series data due to boundary noise. Consider a single foreground pixel belonging to 
an identified particle which is experimentally
constrained to be stationary, and which is adjacent to a background pixel because it is on the edge of the identified 
region. In the next image in the time series, this pixel's intensity is reduced and it is identified as a background
pixel.  If we are calculated particle position as the average of all the identified pixels, this will result in 
the calculated position changing, even if the particle did not physically move. The next frame after that, it 
may be re-identified as a foreground pixel.  While the effect is small, experimental conditions may magnify
these effects and produce appreciable fluctuations in the position and orientation. One way to get around this issue
is to calculate a particle ``skeleton'' which is less sensitive to this form of noise.~\cite{soille-book}

For a rod, we calculate a backbone very similar to the backbone calculated in the Mohraz-Solomon algorithm; but rather 
than using an intensity gradient, we instead calculate with respect to the particle geometry. For each particle, we 
isolate its pixels from the environment (i.e., generate a new image containing only this particle). We then
calculate the distance transform to allow identification of particles which are closest to the 
geometric backbone.  These are identified by applying a ``percentile threshold'' in which the all pixels which
fall below a given percentile in the distribution are reassigned as background pixels. 
The correct value of this threshold is determined by the analysis of a trial image from the image set,
and typically falls in the 85--95\% range.

\subsection{Calculation of position and orientation}

Position and orientation are calculated from particle backbones 
in an identical fashion as in Mohraz and Solomon~\cite{rods-mohraz}; see
Section~\ref{sec:orient-calculate} for details.

\subsection{Time-series tracking}

Building a set of particle trajectories from the frame-by-frame list of particle positions
was accomplished using the Blair and Dufrense implementation~\cite{blair-dufrense-matlab} of 
the tracking procedure developed by Crocker and Grier~\cite{crocker-grier-spheres} and outlined 
in Section~\ref{sec:time-tracking}, with the orientation information ignored for the purposes of
tracking and simple ``carried along'' with the corresponding position data.


\section{Results and discussion}
\label{sec:track-results}

\subsection{Dynamics}

\figone{fig:example-diffusion-results}{figures/computerized-tracking/rod-diffusion-results-old.jpg}{0.6\linewidth}{
Translational and rotational diffusion results for 12~\microns~SFL-fabricated rods.}

Poly(ethylene glycol) diacrylate rods with dimensions 5 \by 3 \by 3 \microns~were fabricated via 
stop-flow lithography, suspended in 
water, and their diffusion was observed as described in Section~\ref{sec:exp-diffusion} with an 
image collection
rate of 2 
frames per second.  The resulting image sequence was imported into Matlab, and tracking was carried out
using the scripts outlined in Section~\ref{sec:matlab-implementation}.  Noise reduction was carried out using 
a band-pass filter with noise and particle dimensions of 1 pixel and 30 pixels respectively. 
Watershed segmentation was carried out using a \texttt{height} parameter of 1, and skeletonization
was performed using a percentile filter of value 0.95 to produce backbones.  The maximum allowable 
displacement between subsequent frames, \texttt{maxdisp}, was set to be 15 pixels.  Finally, the 
MSD of translational and rotational diffusion were calculated and averaged to prodice the results in 
Figure~\ref{fig:example-diffusion-results}.

A series of experiments was carried out to study the effect of rod size and aspect ratio on 2D diffusion, as 
detailed later in Section~\ref{sec:rod-diffusion-results}.

\subsection{Structure}

\figone{fig:track-assembly}{figures/assembled-janus-tracked.png}{0.5\linewidth}{
Assembled Janus rods are tracked.}

Janus rods are fabricated with hydrophilic and hydrophobic components to induce self-assembly.
In Figure~\ref{fig:track-assembly}, the results of a 2D image analysis for aligned Janus clusters
are shown.  This analysis is carried out using the morphological clean-up process with
a top-hat structuring element of radius 40, a opening structuring element of
radius 2, and the default thresholding method. Segmentation was carried out using a 
\texttt{height} parameter of 4, and skeletonization used a percentile threshold of 0.9.  A 
\texttt{cutoff} value of 50 was used in the position calculation step.

A series of experiments was carried out to study the self-assembly of Janus rods, varying
the solvent conditions for assembly and rod aspect ratio.  Orientational ordering and
number of nearest neighbors are calculated across this experiment series; the results are
detailed in Section~\ref{sec:assembly-janus-rods}.
