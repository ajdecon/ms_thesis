\chapter{Computerized Tracking of Anisotropic Colloids}
\section{Introduction}

Confocal laser scanning microscopy (CLSM) is a powerful technique for the study of three-dimensional
structure in fluorescent materials. When applied to fluorescent colloids, CLSM enables the observation
and identification of individual particles, determining their positions in three-dimensional space.
These particle locations alone can be used to derive a great deal
of information about the material, such as the distribution of number of nearest neighbors and
the pair distribution function (PDF). Repeated observations at regular intervals allow for dynamical
measurements of parameters such as the diffusion constant, and may be used to study the microstructual
differences between different parts of the colloidal phase diagram. CLSM has the additional advantage
that since it produces real-space position data, it has substantial advantages over scattering techniques
in coping with samples with highly asymmetric structures.~\ref{?}

However, 
the production of 3D structural information requires more than just a powerful imaging technique: it also
requires powerful computational analysis to translate image data into a list of particles and positions, and
to determine the relevant physical data from this list.  In addition, the behavior of non-spherical colloids
is governed not only by the relative positions of the particles but also their orientations. Developing an
understanding of anisotropic colloids
therefore calls for the development of image processing techniques for the extraction and analysis of
structural data from microscopy images.

\section{Literature review}

\subsection{Particle tracking with spherical colloids}

The current state of the art in 

\subsection{Solomon rod tracking}

\tempfigure{Illustration of Solomon technique}
\tempfigure{SFL particles as 2D extruded objects; flat fluorescence}
\begin{itemize}
\statement{Desirable to locate anisotropic particles in microscopy images to study dynamics and assembly.}
\statement{Previous work in this area: Crocker and Grier, Solomon}
\statement{Can't use Solomon method: fluorescence is too flat for SFL particles. 2D-extruded objects. (Figure to illustrate.)}
\statement{Must develop new algorithms which can work on these particles.}
\end{itemize}

\section{Rod-tracking algorithm}

Our algorithm for locating and tracking SFL rods draws heavily from the algorithm published by 
Mohraz and Solomon for tracking PMMA rods.~\ref{moraz-solomon-rods}.  Briefly, this algorithm 
took advantage of the gradient in fluorescent intensity throughout the volume of the 
rods they studied, which were fabricated by stretching spherical PMMA particles along a single axis.
Because these rods had a circular cross-section, scanning the confocal laser through a point nearer
to the rod axis would pass through a greater volume of fluorescent material, producing a higher intensity.
By applying a local line maximum criterion to the points inside the particle volume, they were able to 
build a ``backbone'' of points near the axis, allowing them to reliably calculate orientation.

While this algorithm performs very well for a restricted class of rods, it fails in cases where the particle
cross-section is not circular, and points near the particle backbone are not guaranteed to produce higher 
intensities than their immediate neighbors.  This is the case for our ``rods'' produced by stop-flow
lithography (SFL), in which the sides of the rods are relatively flat due to the fabrication
geometry. These particles have correspondingly flat fluorescence profiles, and require a more complex analysis
to calculate a ``backbone''.

We have developed an algorithm for processing 2D and 3D CLSM data of fluorescent SFL rods to
produce position and orientaion data.  Starting from raw CLSM images, this algorithm can be divided
into several phases, including (i) image cleanup; (ii) segmentation; (iii) skeletonization;
(iv) position calculation; and
(v) particle tracking over the time series.  

A note on terminology: the algorithm described below is identical for both 2D and 3D images, as all
operations are defined for both cases and used identically. However, where the individual elements of
2D images are referred to as pixels, the elements of 3D images are generally referred to as voxels.
For simplicity, all such elements are referred to as pixels in the explanation below.

\subsection{Image cleanup}

Two different image cleanup methods were considered, and used depending on their effectiveness with
sample data.

The first method, a real-space bandpass filter, is derived from the filter published in the 
Matlab implementation of spherical particle tracking~\ref{crocker-weeks} by Blair and
Dufrense. This filter performs a band-pass by convolving the image with two kernels: 
a Gaussian kernel and a boxcar kernel.  The Gaussian convolution performs the low-pass
operation, while subtracting the result of the boxcar convolution from the Gaussian result
performs the high-pass operation. This filter takes two parameters, the characteristic scale
of image noise (generally equal to one pixel) and the typical particle size.  This works well,
but has issues in images with multi-pixel noise.

While the band-pass performed well on most images, some experiments produced data with noise or
extraneous features which did
not easily yield to the bandpass operation. This can be attributed to the fact that SFL fabrication produces
solutions which have some amount of fluorescent monomer present in the liquid as well as the particles, which
could not always be removed effectively.  A second method was devised using morpholohical
operations to better neutralize non-particle features.

This method may be divided into four steps. First the image is thresholded to produce a binary image, where the 
background is black and the fluorescent features are white. The threshold is selected such that pixels which 
are part of the particle volume are never assigned to the background; Otsu's criterion was found to be reliable
for this.~\ref{?}  Second, a binary opening is applied with an isotropic structuring element to
suppress small features. The size of the structuring element is selected manually by the user, but a 
reliable choice was found to be a diameter roughly equal to half the width of the typical rod. 

At this point a binary image has been produced which suppresses most non-particle features, but morphological
image operations are not guaranteed to preserve shape and orientation of image features.  To retain the noise suppresion
but regain the original shape, we perform one additional morphological dilation using the same structuring element to
guarantee that the foreground regions fully overlap with the rods, then perform a binary AND between the result and the
original image. This is effectively equivalent to using the result of our morphological operations as a mask on
the original, suppressing
all pixels which are marked as background.

\subsection{Segmentation}

The next step of the algorithm is image segmentation, in which individual particles are identified and each pixel
in the image is assigned to a specific particle, or to the background. This is especially important in the study 
of Janus rods, which are come into contact during self-assembly and which therefore often touch or overlap in 
CLSM images. 

First, the image is thresholded to produce a binary image, with a threshold selected such that all pixels which
are part of the rods are assigned to the foreground. This may generally be accomplished through the use of 
Otsu's criterion.~\ref{?}

Second, the distance transform is calculated.  In this step, each foreground pixel is assigned a number which
gives the distance between this pixel and the nearest background pixel. In this algorithm, the distance measure used
is simple Euclidean distance, calculated center-to-center between this pixel and the closest background pixel.  Alternative
distance measures such as the ``chessboard'' measure may also be used to speed up computation, but these measures were
found to negatively impact segmentation.  To prepare the image for watershed segmentation, the distance 
transform is transformed such that all distances are made
negative, while the background remains at a flat zero. An h-minima transform is applied to remove small local minima
due to noise in the image.

The primary segmentation step is the watershed transform. In this transform, a gray-level image is viewed as
a topographic relief map where the pixel values represent altitude. A drop of water falling on a relief 
surface will run down to a minimum, and many drops will fill any basins present until the basins merge.
Implementations of the watershed transform use this concept to calculate the boundaries between catchment basins,
fully segmenting the image.  The number of basins is calculated either by using local minima in the image, or by 
pre-assigning a set of markers.  In our algorithm, we generally use the Matlab implementation of \texttt{watershed} which
uses the local minima method.  This carries some danger of over-segmentation (mitigated somewhat by the 
h-minima transform), but is better suited to automatic processing of a large number of images than manual markers.

\texttt{watershed} outputs an image which labels each pixel according to a region ID number, and labels both background
and foreground pixels with these regions. To restrict these labels so that the background is labeled separately, all 
watershed pixels which correspond to background-valued pixels in the thresholded image are assigned a label number of zero.

\subsection{Skeletonization}

Once we have identified which image pixels belong to each particle, we need to put this data into a form from
which reliable position and orientation information can be calculated.  While it is tempting to simply
calculate the centroid and associated moments from the raw pixel data, this can be problematic when working with
time-series data due to boundary noise. Consider a single foreground pixel belonging to 
an identified particle which is experimentally
constrained to be stationary, and which is adjacent to a background pixel because it is on the edge of the identified 
region. In the next image in the time series, this pixel's intensity is reduced and it is identified as a background
pixel.  If we are calculated particle position as the average of all the identified pixels, this will result in 
the calculated position changing, even if the particle did not physically move. The next frame after that, it 
may be re-identified as a foreground pixel.  While the effect is small, experimental conditions may magnify
these effects and produce appreciable fluctuations in the position and orientation. One way to get around this issue
is to calculate a particle ``skeleton'' which is less sensitive to this form of noise.

For a rod, we calculate a backbone very similar to the backbone calculated in the Mohraz-Solomon algorithm; but rather 
than using an intensity gradient, we instead calculate with respect to the particle geometry. For each particle, 
we calculate the distance transform and apply a local line maximum constraint. The line maximum constraint is applied
for eight line orientations, and the pixel is considered a backbone pixel if a certain number of these are
satisfied (typically 50\%).

\subsection{Calculation of position and orientation}

Position and orientation calculated by Solomon...

\subsection{Particle tracking}

Tracking via Crocker...

\section{Tracking arbitrary particles}

\subsection{Skeletonization}

\subsection{Representative skeleton}

\subsection{Rotation/comparison}


\tempfigure{Image processing flowchart}
\tempfigure{Example image: cleanup, segmentation, skeleton, track}
\tempfigure{Schematic comparison of 2D/3D}
\tempfigure{Schematic explanation of ``template'' technique for tracking arbitrary shapes}
\tempfigure{Example images for ``template'' tracking}
\begin{itemize}
\notdone{Tracking algorithm for arbitrary shapes}

\begin{itemize}
\done{Initial steps same as for rods: cleanup, segmentation}
\done{``Skeletonization'' as above, but producing a more complex skeleton than for rods}
\done{Calculate center-of-mass as with rods}
\done{Choose a sample skeleton as the ``canonical'' particle skeleton}
\done{Isolate particles into individual windows}
\done{To measure orientation: rotate canonical skeleton image in small increments. For each one, AND together the 
rotated skeleton and the sample skeleton.  Maximize pixel sum of ANDed image.}
\done{Faster in 2D than in 3D}
\notdone{Implementation not finished!}
\end{itemize}

\end{itemize}

\section{Implementation}

\tempfigure{Example particle tracks}
\begin{itemize}
\done{Rod tracking implemented in 2D in Matlab.}
\statement{Go over the details of the matlab implementation}
\notdone{Rod tracking implemented in 3D in Matlab, but with major bugs.}
\notdone{Arbitrary tracker not yet fully implemented, using Matlab.}
\end{itemize}

\section{Assessment}

\tempfigure{Cartoons to show possible errors}
\begin{itemize}
\done{Identify issues caused by morphological image processing for these algorithms.}
\notdone{Estimate errors in particle segmentation}
\notdone{Estimate error of rod COM and orientation calculations.}
\notdone{Estimate error of skeleton-based orientation calculations.}
\end{itemize}
