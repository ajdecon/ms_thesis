\chapter{Computerized Tracking of Anisotropic Colloids}
\section{Introduction}

Confocal laser scanning microscopy (CLSM) is a powerful technique for the study of three-dimensional
structure in fluorescent materials. When applied to fluorescent colloids, CLSM enables the observation
and identification of individual particles, determining their positions in three-dimensional space.
These particle locations alone can be used to derive a great deal
of information about the material, such as the distribution of number of nearest neighbors and
the pair distribution function (PDF). Repeated observations at regular intervals allow for dynamical
measurements of parameters such as the diffusion constant, and may be used to study the microstructural
differences between different parts of the colloidal phase diagram. CLSM has the additional advantage
that since it produces real-space position data, it has substantial advantages over scattering techniques
in coping with samples with highly asymmetric structures.~\ref{?}

However, 
the production of 3D structural information requires more than just a powerful imaging technique: it also
requires powerful computational analysis to translate image data into a list of particles and positions, and
to determine the relevant physical data from this list.  In addition, the behavior of non-spherical colloids
is governed not only by the relative positions of the particles but also their orientations. Developing an
understanding of anisotropic colloids
therefore calls for the development of image processing techniques for the extraction and analysis of
structural data from microscopy images.

\section{Algorithm}
\label{sec:rod-tracking}

Our method for locating and tracking SFL rods draws heavily from that published by 
Mohraz and Solomon for tracking PMMA rods.~\ref{moraz-solomon-rods}.  Briefly, this algorithm 
took advantage of the gradient in fluorescent intensity throughout the volume of the 
rods they studied, which were fabricated by stretching spherical PMMA particles along a single axis.
Because these rods had a circular cross-section, scanning the confocal laser through a point nearer
to the rod axis would pass through a greater volume of fluorescent material, producing a higher intensity.
By applying a local line maximum criterion to the points inside the particle volume, they were able to 
build a ``backbone'' of points near the axis, allowing them to reliably calculate orientation.

While this algorithm performs very well for a restricted class of rods, it fails in cases where the particle
cross-section is not circular, and points near the particle backbone are not guaranteed to produce higher 
intensities than their immediate neighbors.  This is the case for our ``rods'' produced by stop-flow
lithography (SFL), in which the sides of the rods are relatively flat due to the fabrication
geometry. These particles have correspondingly flat fluorescence profiles, and require a more complex analysis
to calculate a ``backbone''.

We have developed an algorithm for processing 2D and 3D CLSM data of fluorescent SFL rods to
produce position and orientation data.  Starting from raw CLSM images, this algorithm can be divided
into several phases, including (i) image cleanup; (ii) segmentation; (iii) skeletonization;
(iv) position calculation; and
(v) particle tracking over the time series.  

A note on terminology: the algorithm described below is identical for both 2D and 3D images, as all
operations are defined for both cases and used identically. However, where the individual elements of
2D images are referred to as pixels, the elements of 3D images are generally referred to as voxels.
For simplicity, all such elements are referred to as pixels in the explanation below.

\subsection{Image cleanup}

Two different image cleanup methods were considered, and used depending on their effectiveness with
sample data.

The first method, a real-space bandpass filter, is derived from the filter published in the 
Matlab implementation of spherical particle tracking~\ref{crocker-weeks} by Blair and
Dufrense. This filter performs a band-pass by convolving the image with two kernels: 
a Gaussian kernel and a boxcar kernel.  The Gaussian convolution performs the low-pass
operation, while subtracting the result of the boxcar convolution from the Gaussian result
performs the high-pass operation. This filter takes two parameters, the characteristic scale
of image noise (generally equal to one pixel) and the typical particle size.  This works well,
but has issues in images with multi-pixel noise.

While the band-pass performed well on many images, some experiments produced data with noise or
extraneous features which did
not easily yield to the bandpass operation. This can be attributed to the fact that SFL fabrication produces
solutions which have some amount of fluorescent monomer present in the liquid as well as the particles, which
could not always be removed effectively.  A second method was devised using morphological
operations to better neutralize non-particle features.

This method may be divided into five steps. First, the 
image is run through a morphological top-hat transform. This transform is used to account for the effects of
uneven illumination in the image. Then the image is thresholded to produce a binary image, where the 
background is black and the fluorescent features are white. The threshold is selected such that pixels which 
are part of the particle volume are never assigned to the background; Otsu's criterion was found to be reliable
for this.~\ref{?}  Next, a binary opening is applied with an isotropic structuring element to
suppress small features. The size of the structuring element is selected manually by the user, but a 
reliable choice was found to be a diameter roughly equal to half the width of the typical rod. 

At this point a binary image has been produced which suppresses most non-particle features, but morphological
image operations are not guaranteed to preserve shape and orientation of image features.  To retain the noise suppression
but regain the original shape, we perform one additional morphological dilation using the same structuring element to
guarantee that the foreground regions fully overlap with the rods, then perform a binary AND between the result and the
original image. This is effectively equivalent to using the result of our morphological operations as a mask on
the original, suppressing
all pixels which are marked as background.

\subsection{Segmentation}

The next step of the algorithm is image segmentation, in which individual particles are identified and each pixel
in the image is assigned to a specific particle, or to the background. This is especially important in the study 
of Janus rods, which are come into contact during self-assembly and which therefore often touch or overlap in 
CLSM images. 

First, the image is thresholded to produce a binary image, with a threshold selected such that all pixels which
are part of the rods are assigned to the foreground. This may generally be accomplished through the use of 
Otsu's criterion.~\ref{?}

Second, the distance transform is calculated.  In this step, each foreground pixel is assigned a number which
gives the distance between this pixel and the nearest background pixel. In this algorithm, the distance measure used
is simple Euclidean distance, calculated center-to-center between this pixel and the closest background pixel.  Alternative
distance measures such as the ``chessboard'' measure may also be used to speed up computation, but these measures were
found to negatively impact segmentation.  To prepare the image for watershed segmentation, the distance 
transform is transformed such that all distances are made
negative, while the background remains at a flat zero. An h-minima transform is applied to remove small local minima
due to noise in the image.

The primary segmentation step is the watershed transform. In this transform, a gray-level image is viewed as
a topographic relief map where the pixel values represent altitude. A drop of water falling on a relief 
surface will run down to a minimum, and many drops will fill any basins present until the basins merge.
Implementations of the watershed transform use this concept to calculate the boundaries between catchment basins,
fully segmenting the image.  The number of basins is calculated either by using local minima in the image, or by 
pre-assigning a set of markers.  In our algorithm, we generally use the Matlab implementation of \texttt{watershed} which
uses the local minima method.  This carries some danger of over-segmentation (mitigated somewhat by the 
h-minima transform), but is better suited to automatic processing of a large number of images than manual markers.

\texttt{watershed} outputs an image which labels each pixel according to a region ID number, and labels both background
and foreground pixels with these regions. To restrict these labels so that the background is labeled separately, all 
watershed pixels which correspond to background-valued pixels in the thresholded image are assigned a label number of zero.

\subsection{Skeletonization}

Once we have identified which image pixels belong to each particle, we need to put this data into a form from
which reliable position and orientation information can be calculated.  While it is tempting to simply
calculate the centroid and associated moments from the raw pixel data, this can be problematic when working with
time-series data due to boundary noise. Consider a single foreground pixel belonging to 
an identified particle which is experimentally
constrained to be stationary, and which is adjacent to a background pixel because it is on the edge of the identified 
region. In the next image in the time series, this pixel's intensity is reduced and it is identified as a background
pixel.  If we are calculated particle position as the average of all the identified pixels, this will result in 
the calculated position changing, even if the particle did not physically move. The next frame after that, it 
may be re-identified as a foreground pixel.  While the effect is small, experimental conditions may magnify
these effects and produce appreciable fluctuations in the position and orientation. One way to get around this issue
is to calculate a particle ``skeleton'' which is less sensitive to this form of noise.

For a rod, we calculate a backbone very similar to the backbone calculated in the Mohraz-Solomon algorithm; but rather 
than using an intensity gradient, we instead calculate with respect to the particle geometry. For each particle, we 
isolate its pixels from the environment (i.e., generate a new image containing only this particle). We then
calculate the distance transform to allow identification of particles which are closest to the 
geometric backbone.  These are identified by applying a ``percentile threshold'' in which the all pixels which
fall below a given percentile in the distribution are reassigned as background pixels. Typical cutoffs used
are 90-95\%, depending on trial images.

\subsection{Calculation of position and orientation}

\figone{fig:coordinates}{figures/computerized-tracking/rod-schematic-solomon.png}{0.5\linewidth}{
Positional and orientational coordinates for colloidal rods.~\cite{solomon-rods}}

Once the backbone pixels for a given rod have been identified, the position and orientation of each rod may
be determined based on these pixels' locations.  Each rod's geometric configuration can be
completely specified by three positional coordinates, $x$, $y$ and $z$, and two
orientational coordinates $\theta$ and $\phi$, as shown in~\ref{fig:coordinates}.
The equations for performing this calculation,
\ref{eq:x-cent}--\ref{eq:phi}, are taken from 
Mohraz and Solomon, \textit{Langmuir} (2007)~\cite{solomon-rods}.

The rod's center-of-mass position may be calculated
straightforwardly based on a simple average over the positions of the backbone pixels.  In 
\ref{eq:x-cent}--\ref{z-cent}, $r_{0,i}$ represents the center-of-mass of coordinate $r$ for 
rod $i$.  $S_i$ is the set of identified backbone pixels associated with that rod, and $s$ is the index
variable summing over that set..

\begin{equation}
\label{eq:x-cent}
x_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} x_{s,i}
\end{equation}
\begin{equation}
\label{eq:y-cent}
y_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} y_{s,i}
\end{equation}
\begin{equation}
\label{eq:z-cent}
z_{0,i} = \frac{1}{S_i} \sum_{s}^{S_i} z_{s,i} 
\end{equation}

Calculating orientation is somewhat more complex.  First, for each dimension $r$, the quantity
$|<l_r^2>^{1/2}|$ is calculated (\ref{eq:x-len}--\ref{z-len}). 
Geometrically, this is the size of the projection of the rod's length
onto the axis $r$, and it is equivalent to the standard deviation of the $r$ coordinate.
Once these dimensions have been calculated, the angles $\phi$ and $\theta$ may be 
determined according to \ref{eq:phi} and \ref{eq:theta}, respectively.

\begin{equation}
\label{eq:x-len}
|<l_x^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (x_{s,i} - x_{0,i} )^2 \right]^{1/2}
\end{equation}
\begin{equation}
\label{eq:y-len}
|<l_y^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (y_{s,i} - y_{0,i} )^2 \right]^{1/2}
\end{equation}
\begin{equation}
\label{eq:z-len}
|<l_z^2>_i^{1/2}| = \left[\frac{1}{S_i} \sum_s^{S_i} (z_{s,i} - z_{0,i} )^2 \right]^{1/2}
\end{equation}

\begin{equation}
\label{eq:theta}
\theta_i = \cos^{-1} \left(\frac{<l_z^2>_i^{1/2}}{<l^2>_i^{1/2}} \right)
\end{equation}
\begin{equation}
\label{eq:phi}
\phi_i = \tan^{-1} \left(\frac{<l_y^2>_i^{1/2}}{<l_x^2>_i^{1/2}} \right)
\end{equation}

\subsection{Algorithm summary}

\begin{enumerate}

\item \textbf{Image cleanup}
    \begin{itemize}
    \item Option 1: band-pass filter to suppress noise.~\cite{crocker}
    \item Option 2: morphological processing
        \begin{enumerate}
        \item Top-hat transform.
        \item Threshold.
        \item Morphological opening.
        \item Morphological dilation.
        \item Binary AND with original.
        \end{enumerate}
    \end{itemize}

\item \textbf{Segmentation}
    \begin{enumerate}
    \item Distance transform.
    \item H-minima transform.
    \item Watershed transform.
    \end{enumerate}

\item \textbf{Skeletonization}
    \begin{enumerate}
    \item Rod isolation.
    \item Distance transform.
    \item Percentile threshold filter.
    \end{enumerate}

\item \textbf{Coordinate calculation}
    \begin{enumerate}
    \item Positional coordinates: \ref{eq:x-cent}--\ref{eq:z-cent}
    \item Calculation of length projections: \ref{eq:x-len}--\ref{eq:z-len}
    \item Orientational coordinates: \ref{eq:theta}--\ref{eq:phi}
    \end{enumerate}

\end{enumerate}

\section{Implementation}
\label{sec:matlab-implementation}

The results of typical experiments with samples of single-component or Janus rods included both 
large-area tiled images taken of many particles at a single time,
used to study static self-assembly, and movies consisting of many subsequent images in a 
particular location, taken to study dynamical behavior.  Each of these experimental types required the processing
of image sets numbering in the hundreds or thousands.  The analysis of these images using the algorithm developed
above requires the selection of a number of input parameters, such as the thresholding levels and the 
structuring elements for morphological processing.  However, while all the images from a typical
experiment could be expected to share the same parameter values, those values might vary considerably for the 
analysis of different
experiments.

To address this, we implemented our algorithm as a set of independent functions which could be carried out manually 
or called from an automated script. A typical analysis was carried out by selecting one or more 
test images from the data set; carrying out the various image processing steps on these test images, varying
the processing parameters to obtain the best results; and then calling the automation script using the 
optimized values to process the entire data set.  Analysis of test images was generally carried out on a single
workstation, while full-dataset processing was carried out on dedicated servers to maximize processing efficiency.

All steps of the analysis were implementing in Matlab~\cite{matlab}, making heavy use of functions from the
Image Processing Toolbox.  The following description summarizes the process of carrying out a manual analysis of
test images as a guide to future users; a full source-code listing can be found in~\ref{sec:matlab-code}.

\pagebreak

\begin{lstlisting}[label=ls:manual,caption=Typical sequence of a manual analysis]
% Load the image.
img = imread('filename.tif');

% If using bandpass cleaning.
clean = bpass(img,lnoise,lobject);

% If using morphological cleaning.
%  top-hat step: radius 50 is greater than rod size.
%  opening step: radius 2 is a good size for eliminating small variations.
thstruct = strel('disk',50);
opstruct = strel('disk',2);

% Segmentation step.
watershed_labels = segment(clean, 1);

% Now find backbone pixels.
skeletons = backbones(clean, watershed_labels, 90);

% Finally get the list of positions.
positions = calc_positions(skeletons);
\end{lstlisting}

\subsection{Image cleanup}

Image cleanup is probably the part of the analysis which is most sensitive to parameter selection.
Original images of colloidal rod samples from CLSM or FM are often noisy or unevenly illuminated, and these
effects vary from experiment to experiment.  However, subsequent steps of the analysis assume that their input
images will be simple binary images, with white rods and a black background. Choosing the correct parameters 
to produce such images is a matter of trial and error, and the particular choices must be re-optimized
for each new experiment.  Two options exist for performing this clean-up: a simple bandpass filter, 
and a more complex set of morphological operations.

\subsubsection{Option 1: band-pass}

\texttt{clean = bpass(image\_array, lnoise, lobject[, threshold])}

\begin{itemize}
\item \texttt{image\_array}: Matlab array containing image pixels.
\item \texttt{lnoise}: Characteristic length-scale of noise.
\item \texttt{lobject}: Characteristic length-scale of object to be tracked (i.e., length of a colloidal rod).
\item \texttt{threshold}: By default, the last step of this algorithm is to set all negative pixels (generated
by the convolution) to be zeros. This parameter may optionally be used to apply a threshold with a different cut-off.
\end{itemize}

\texttt{bpass.m} is from the Blair and Dufrense~\cite{blair-matlab} Matlab implementation of the Crocker and Weeks
package for tracking of spherical particles.~\cite{crocker-tracking}

\subsubsection{Option 2: morphological cleanup}

\texttt{clean = mclean(img, thstruct, opstruct[, threshold])}

\begin{itemize}
\item \texttt{img}: Matlab array containing image pixels.
\item \texttt{thstruct}: Matlab structuring element used to carry out the top-hat transform.
\item \texttt{opstruct}: Matlab structuring element used to carry out the opening and dilation operations.
\item \texttt{threshold}: By default, the threshold used in this algorithm is selected using the built-in
Matlab function \texttt{graythresh}, which uses Otsu's algorithm~\cite{?}. Here, the user may optionally
select a different threshold.
\end{itemize}

\subsection{Segmentation}

\texttt{watershed\_img = segment(img[, height])}

\begin{itemize}
\item \texttt{img}: Matlab array containing the image pixels.
\item \texttt{height}: Maximum height to suppress in h-minima transform. Optional, defaults to 1.
\end{itemize}

\texttt{segment.m} carries out the image segmentation part of the algorithm, and consists of three calls to
Matlab built-in functions: \texttt{bwdist}, which carries out the distance transform, 
\texttt{imhmin}, which carries out the h-minima transform, and \texttt{watershed}, which performs watershed
segmentation. While these processes are all computationally intensive, the result is relatively insensitive to
processing parameters. The only parameter available is the height of the h-minima transform, which is generally
set to 1 to account for single-pixel fluctuations; 
it is increased only when over-segmentation is observed in the resulting watershed.~\ref{fig:over-segment}
To observe the resulting watershed segmentation, use the code in Listing~\ref{ls:showwater}.

\begin{lstlisting}[label=ls:showwater,caption=Observe watershed segmentation]
imshow( label2rgb(watershed_img,'jet') );
\end{lstlisting}

\subsection{Skeletonization}

\texttt{skeletons = backbones(img, watershed\_img, percent)}

\begin{itemize}
\item \texttt{img}: Matlab array containing the image pixels.
\item \texttt{watershed\_img}: Image containing the watershed labels.
\item \texttt{percent}: Percentile used in the thresholding step.
\end{itemize}

The generation of the rod skeletons, carried out in \texttt{backbones.m}, is also a relatively simple
procedure.  The results of the watershed segmentation step are used to find the portion of the 
image which contains each rod, and this is used to generate a new image in which the rod may
be analyzed in isolation. The only choice which must be made is the percentile threshold for selecting 
backbone pixels. This is again a matter of trial and error, but typical values are in the range of 90-95\%.

A final image is generated which contains all the backbones, with the pixels belonging to each one having
the value of their watershed label. This allows them to be uniquely identified in the following step. The background is 
assigned again to zero.  Observation of these backbones for quality check requires a thresholding step. Observation
of all the backbones may be accomplished using the code in Listing~\ref{ls:allbb}, while observing only the backbone 
with label $n$ may be accomplished using the code in Listing~\ref{ls:onebb}.

\begin{lstlisting}[label=ls:allbb,caption=Show all backbones as an image]
imshow(im2bw(skeletons, 0));
\end{lstlisting}

\begin{lstlisting}[label=ls:onebb,caption=Show only backbone with label $n$]
temp=skeletons;
temp(temp~=n)=0;
imshow(im2bw(skeletons, 0));
\end{lstlisting}

\subsection{Coordinate calculation}

\texttt{positions = calc\_positions(skeletons[, cutoff])}

\begin{itemize}
\item \texttt{skeletons}: Image containing the rod skeletons.
\item \texttt{cutoff}: Optional parameter listing a cut-off for ignoring a backbone.
\end{itemize}

For each individual rod, \texttt{calc\_positions.m} calculates the positional and
orientational coordinates and saves them to the array \texttt{positions}.  
\texttt{cutoff} is an optional parameter which allows \texttt{calc\_positions.m} to 
ignore backbones which contain under a certain number of pixels, as one last noise-protection step.

\texttt{positions} is a 2D Matlab array in which each row represents one backbone, and has 
the structure:

\begin{tabular}{ | c | c | c | c | c | }
\hline 
$x$ & $y$ & $z$ & $\phi$ & $\theta$ \\
\hline
\end{tabular}

In any 2D image, $z$ and $\theta$ are always zero.

\subsection{Automated analysis of time series}

\texttt{poslist = rod\_tseries\_bp(imgstack,lnoise,lobject,threshold,height,percent)}

\texttt{poslist = rod\_tseries(imgstack,thstruct,opstruct,threshold,height,percent)}

\subsection{Temporal tracking}

\texttt{tracks = track(xyzs, maxdisp, param)}

\begin{itemize}
\item \texttt{xyzs}: An array containing a time-sorted list of particle positions (and, here, orientations).
\item \texttt{maxdisp}: Maximum allowed displacement of a particle between frames.
\item \texttt{param}: A data structure containing additional processing parameters.
\end{itemize}

Frame-to-frame tracking of unique rods to form trajectories was accomplished using a Matlab routine, \texttt{track.m}, 
supplied by Blair and Dufrense~\cite{blair-matlab}, implementing the standard algorithm for particle tracking by
Crocker and Weeks~\cite{crocker-tracking}.  \texttt{track.m} requires that the data be in a time-sorted format where each
row consists of a list of coordinates followed by a frame number, and the frame numbers increase monotonically.

The output, \texttt{tracks}, is in a similar format which includes one extra column: a particle ``id number'' which
allows each trajectory to be identified. Rows are ordered so that particle id number increases monotonically, and
time increases monotonically within each set of particle rows.

The optional input structure, \texttt{param}, contains a variety of settings which alter the behavior of 
\texttt{track}.  The only setting important to this analysis is \texttt{param.dim}, which tells the program how
many columns to use as positional dimensions. Any additional columns will be ignored in the tracking calculation and 
simply ``carried along'' when the new array is built; this gives us a place to put our orientation coordinates, which
will not be used in the tracking routine.

\subsection{Visualization}

\texttt{singleframe(img,positions)}

\texttt{rodmovie(imgstack,poslist)}

\section{Results and discussion}
\figone{fig:example-diffusion-results}{figures/computerized-tracking/rod-diffusion-results-old.jpg}{\linewidth}{
Translational and rotational diffusion results for 12~\microns~SFL-fabricated rods.}


